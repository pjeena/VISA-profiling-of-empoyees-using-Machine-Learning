{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np   \n",
    "import pandas as pd  \n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import scipy.stats as stats\n",
    "import pickle \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import BaggingClassifier,RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, StackingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import mlflow\n",
    "import mlflow.sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DATA_PATH_X = '/Users/piyush/Desktop/dsml_Portfolio/visa/data/processed/X.csv'\n",
    "RAW_DATA_PATH_y = '/Users/piyush/Desktop/dsml_Portfolio/visa/data/processed/y.csv'\n",
    "X = pd.read_csv(RAW_DATA_PATH_X)\n",
    "y = pd.read_csv(RAW_DATA_PATH_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_report(model,features,target):\n",
    "    predictions = model.predict(features)\n",
    "    acc = accuracy_score(target, predictions)  # to compute Accuracy\n",
    "    recall = recall_score(target, predictions)  # to compute Recall\n",
    "    precision = precision_score(target, predictions)  # to compute Precision\n",
    "    f1 = f1_score(target, predictions)  # to compute F1-score\n",
    "\n",
    "        # creating a dataframe of metrics\n",
    "    df_metrics = pd.DataFrame({\n",
    "            \"Accuracy\": acc,\n",
    "            \"Recall\": recall,\n",
    "            \"Precision\": precision,\n",
    "            \"F1 Score\": f1,\n",
    "            },index=[0],)\n",
    "\n",
    "    return df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run():\n",
    "  xgb_model = XGBClassifier(random_state=42, eval_metric='logloss')\n",
    "\n",
    "  # parameters to choose from\n",
    "  parameters = {\n",
    "      \"n_estimators\": [10,30,50],\n",
    "      \"scale_pos_weight\":[1,2,5],\n",
    "      \"subsample\":[0.7,0.9,1],\n",
    "      \"learning_rate\":[0.05, 0.1,0.2],\n",
    "      \"colsample_bytree\":[0.7,0.9,1],\n",
    "      \"colsample_bylevel\":[0.5,0.7,1]\n",
    "  }\n",
    "\n",
    "  # Type of scoring used to compare parameter combinations\n",
    "  scorer = metrics.make_scorer(metrics.f1_score)\n",
    "\n",
    "  #  grid search\n",
    "  grid_obj = GridSearchCV(xgb_model, parameters,scoring=scorer,cv=3)\n",
    "  grid_obj = grid_obj.fit(X_train, y_train)\n",
    "\n",
    "  # Set the clf to the best combination of parameters\n",
    "  xgb = grid_obj.best_estimator_\n",
    "\n",
    "  # Fit the best algorithm to the data.\n",
    "  xgb.fit(X_train, y_train)\n",
    "  \n",
    "  metrics_train = metrics_report(xgb,X_train,y_train)\n",
    "  metrics_test = metrics_report(xgb,X_test,y_test)\n",
    "  metrics_dataframe = pd.concat([metrics_train, metrics_test]).reset_index()\n",
    "  metrics_dataframe['index'] = ['train','test']\n",
    "  metrics_dataframe.set_index('index',inplace=True)\n",
    "\n",
    "\n",
    "  mlflow.log_param(\"random_state\", 42)\n",
    "  mlflow.log_param(\"test_size\", 0.3)\n",
    "  #mlflow.log_params(parameters)\n",
    "  mlflow.log_metrics(dict(metrics_dataframe.loc['train']))\n",
    "  mlflow.log_metrics(dict(metrics_dataframe.loc['test']))\n",
    "  mlflow.sklearn.log_model(xgb, \"model\")\n",
    "  modelpath = \"/Users/piyush/Desktop/dsml_Portfolio/visa/models/models-%s-%s\" % (\"model_XBG_Classifier\", 1)\n",
    "  mlflow.sklearn.save_model(xgb, modelpath)  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('visa': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4d13b7a8a14daaf378b0ce6f841b56bee658cc4951698355cc9e2ea886b41241"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
